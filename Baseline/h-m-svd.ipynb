{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Dependency","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/mayukh18/reco\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm\nfrom reco.recommender import FunkSVD\nfrom reco.metrics import rmse\nimport datetime\nfrom collections import Counter\nfrom datetime import timedelta","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:13:06.849143Z","iopub.execute_input":"2022-05-06T00:13:06.849847Z","iopub.status.idle":"2022-05-06T00:13:52.930715Z","shell.execute_reply.started":"2022-05-06T00:13:06.849708Z","shell.execute_reply":"2022-05-06T00:13:52.929562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data preparation","metadata":{}},{"cell_type":"code","source":"transaction = pd.read_csv(\"../input/h-and-m-personalized-fashion-recommendations/transactions_train.csv\",header=0, dtype={'article_id':str})\n\ntransaction[\"t_dat\"] = pd.to_datetime(transaction[\"t_dat\"])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:13:52.933049Z","iopub.execute_input":"2022-05-06T00:13:52.933411Z","iopub.status.idle":"2022-05-06T00:15:13.830471Z","shell.execute_reply.started":"2022-05-06T00:13:52.933365Z","shell.execute_reply":"2022-05-06T00:15:13.829417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3 Rank articles with the Popularity","metadata":{}},{"cell_type":"code","source":"# in recent 8 weeks\ntrain_pop = transaction.loc[transaction[\"t_dat\"] >= datetime.datetime(2020, 7, 28)]\n# train_pop.loc[:, 'd'] = 0\n\ntrain_pop.loc[:,'num'] = (train_pop[\"t_dat\"].max() - train_pop[\"t_dat\"])\ntrain_pop['pop_factor'] = 1 / (train_pop['num'].dt.days + 1)\npopular_items_group = train_pop.groupby([\"article_id\"])['pop_factor'].sum()\n_, popular_items = zip(*sorted(zip(popular_items_group, popular_items_group.keys()))[::-1])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:15:13.974014Z","iopub.execute_input":"2022-05-06T00:15:13.97472Z","iopub.status.idle":"2022-05-06T00:15:14.995979Z","shell.execute_reply.started":"2022-05-06T00:15:13.97468Z","shell.execute_reply":"2022-05-06T00:15:14.995003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. item2iem","metadata":{}},{"cell_type":"code","source":"def get_most_freq_next_item(user_group):\n    next_items = {}\n    for user in tqdm(user_group.keys()):\n        items = user_group[user]\n        for i,item in enumerate(items[:-1]):\n            if item not in next_items:\n                next_items[item] = []\n#             if item != items[i+1]:\n#                 next_items[item].append(items[i+1])\n            next_items[item].append(items[i+1])\n    \n    pred_next = {}\n    for item in next_items:\n        if len(next_items[item]) >= 5:\n            most_common = Counter(next_items[item]).most_common()\n            ratio = most_common[0][1]/len(next_items[item])\n            if ratio >= 0.1:\n                pred_next[item] = most_common[0][0]\n            \n    return pred_next","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:15:14.997297Z","iopub.execute_input":"2022-05-06T00:15:14.997542Z","iopub.status.idle":"2022-05-06T00:15:15.006523Z","shell.execute_reply.started":"2022-05-06T00:15:14.997512Z","shell.execute_reply":"2022-05-06T00:15:15.005491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# recent 4 weeks;\none_day = timedelta(days=1)\nyear_month_day = str(transaction[\"t_dat\"].max() - one_day*7*4)[:10].split('-')\n\nyear_ = int(year_month_day[0])\nmonth_ = int(year_month_day[1])\nday_ = int(year_month_day[2])\n\nuser_group = transaction.loc[transaction[\"t_dat\"] >= datetime.datetime(year_, month_, day_)].groupby([\"customer_id\"])[\"article_id\"].apply(list)\npred_next = get_most_freq_next_item(user_group)\nuser_group_dict = user_group.to_dict()","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:15:15.007884Z","iopub.execute_input":"2022-05-06T00:15:15.008172Z","iopub.status.idle":"2022-05-06T00:15:25.029135Z","shell.execute_reply.started":"2022-05-06T00:15:15.008128Z","shell.execute_reply":"2022-05-06T00:15:25.027826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.1 FunkSVD\n\nThe Singular Value Decomposition (SVD), a method from linear algebra that has been generally used as a dimensionality reduction technique in machine learning. SVD is a matrix factorisation technique, which reduces the number of features of a dataset by reducing the space dimension from N-dimension to K-dimension (where K<N). In the context of the recommender system, the SVD is used as a collaborative filtering technique. It uses a matrix structure where each row represents a user, and each column represents an item. The elements of this matrix are the ratings that are given to items by users.","metadata":{}},{"cell_type":"code","source":"# recent 16 weeks;\ndf = transaction.loc[transaction[\"t_dat\"] >= datetime.datetime(2020, 6, 2), [\"customer_id\", \"article_id\", \"t_dat\"]].copy()\n\n#define pop_factor for each article;\ndf['num'] = (df[\"t_dat\"].max() - df[\"t_dat\"])\ndf['pop_factor'] = 1 / (df['num'].dt.days + 1)\n\npopular_items_group = df.groupby([\"article_id\"])['pop_factor'].sum()\n\ndf['pop_score'] = 1\ndf = df.groupby([\"customer_id\", \"article_id\"]).sum().reset_index()\ndf['pop_score'] = df.apply(lambda row: row['pop_score']/popular_items_group[row[\"article_id\"]], axis=1)\n#set max score of pop_score to be 5.0\ndf['pop_score'] = df['pop_score'].apply(lambda x: 5.0 if x>5.0 else x)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:16:43.835849Z","iopub.execute_input":"2022-05-06T00:16:43.836202Z","iopub.status.idle":"2022-05-06T00:18:53.776794Z","shell.execute_reply.started":"2022-05-06T00:16:43.836166Z","shell.execute_reply":"2022-05-06T00:18:53.775815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[[\"customer_id\", \"article_id\", 'pop_score']]\n\n# shuffling\ndf = df.sample(frac=1).reset_index(drop=True)\nsvd = FunkSVD(k=8, learning_rate=0.008, regularizer = .01, iterations = 80, method = 'stochastic', bias=True)\nsvd.fit(X=df, formatizer={'user':\"customer_id\", 'item':\"article_id\", 'value':'pop_score'},verbose=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:21:00.19401Z","iopub.execute_input":"2022-05-06T00:21:00.195024Z","iopub.status.idle":"2022-05-06T00:23:52.763691Z","shell.execute_reply.started":"2022-05-06T00:21:00.194958Z","shell.execute_reply":"2022-05-06T00:23:52.762286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.2 Recently Purchase most\n\nGet four train sets from the most recent four weeks;","metadata":{}},{"cell_type":"code","source":"train1 = transaction.loc[(transaction[\"t_dat\"] >= datetime.datetime(2020, 9, 15))]\ntrain2 = transaction.loc[(transaction[\"t_dat\"] >= datetime.datetime(2020, 9, 8)) & (transaction[\"t_dat\"] < datetime.datetime(2020, 9, 15))]\ntrain3 = transaction.loc[(transaction[\"t_dat\"] >= datetime.datetime(2020, 9, 1)) & (transaction[\"t_dat\"] < datetime.datetime(2020, 9, 8))]\ntrain4 = transaction.loc[(transaction[\"t_dat\"] >= datetime.datetime(2020, 8, 25)) & (transaction[\"t_dat\"] < datetime.datetime(2020, 9, 1))]\n\ntmp = train1.groupby([\"customer_id\",\"article_id\"])[\"t_dat\"].agg('count').reset_index()\ntmp.columns = [\"customer_id\",\"article_id\",'cnt']\ntrain1 = train1.merge(tmp, on = [\"customer_id\",\"article_id\"], how='left')\ntrain1 = train1.sort_values([\"t_dat\", 'cnt'],ascending=False)\ntrain1.index = range(len(train1))\npositive_items_per_user1 = train1.groupby([\"customer_id\"])[\"article_id\"].apply(list)\n\n\ntmp = train2.groupby([\"customer_id\",\"article_id\"])[\"t_dat\"].agg('count').reset_index()\ntmp.columns = [\"customer_id\",\"article_id\",'cnt']\ntrain2 = train2.merge(tmp, on = [\"customer_id\",\"article_id\"], how='left')\ntrain2 = train2.sort_values([\"t_dat\", 'cnt'],ascending=False)\ntrain2.index = range(len(train2))\npositive_items_per_user2 = train2.groupby([\"customer_id\"])[\"article_id\"].apply(list)\n\n\ntmp = train3.groupby([\"customer_id\",\"article_id\"])[\"t_dat\"].agg('count').reset_index()\ntmp.columns = [\"customer_id\",\"article_id\",'cnt']\ntrain3 = train3.merge(tmp, on = [\"customer_id\",\"article_id\"], how='left')\ntrain3 = train3.sort_values([\"t_dat\", 'cnt'],ascending=False)\ntrain3.index = range(len(train3))\npositive_items_per_user3 = train3.groupby([\"customer_id\"])[\"article_id\"].apply(list)\n\n\ntmp = train4.groupby([\"customer_id\",\"article_id\"])[\"t_dat\"].agg('count').reset_index()\ntmp.columns = [\"customer_id\",\"article_id\",'cnt']\ntrain4 = train4.merge(tmp, on = [\"customer_id\",\"article_id\"], how='left')\ntrain4 = train4.sort_values([\"t_dat\", 'cnt'],ascending=False)\ntrain4.index = range(len(train4))\npositive_items_per_user4 = train4.groupby([\"customer_id\"])[\"article_id\"].apply(list)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:32:48.589927Z","iopub.execute_input":"2022-05-06T00:32:48.590303Z","iopub.status.idle":"2022-05-06T00:33:00.197395Z","shell.execute_reply.started":"2022-05-06T00:32:48.590263Z","shell.execute_reply":"2022-05-06T00:33:00.196329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/h-and-m-personalized-fashion-recommendations/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:34:38.109698Z","iopub.execute_input":"2022-05-06T00:34:38.110719Z","iopub.status.idle":"2022-05-06T00:34:43.96342Z","shell.execute_reply.started":"2022-05-06T00:34:38.110646Z","shell.execute_reply":"2022-05-06T00:34:43.962531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Get Result\n\nRecursively get the customer in all customers to find whether they are in these four train sets, and according to the result, give corresponding prediction; If not, then give the most 12 popular articles as their prediction;","metadata":{}},{"cell_type":"code","source":"result = []\n\nuserindexes = {svd.users[i]:i for i in range(len(svd.users))}\nfor user in tqdm(sub[\"customer_id\"].unique()):\n    user_output = []\n    if user in positive_items_per_user1.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user1[user]).most_common()}\n        user_index = userindexes[user]\n        new_order = {}\n        for k in list(most_common_items_of_user.keys())[:20]:\n            try:\n                itemindex = svd.items.index(k)\n                pred_value = np.dot(svd.userfeatures[user_index], svd.itemfeatures[itemindex].T) + svd.item_bias[0, itemindex]\n            except:\n                pred_value = most_common_items_of_user[k]\n            new_order[k] = pred_value\n        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n        \n    elif user in positive_items_per_user2.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user2[user]).most_common()}\n        user_index = userindexes[user]\n        new_order = {}\n        for k in list(most_common_items_of_user.keys())[:20]:\n            try:\n                itemindex = svd.items.index(k)\n                pred_value = np.dot(svd.userfeatures[user_index], svd.itemfeatures[itemindex].T) + svd.item_bias[0, itemindex]\n            except:\n                pred_value = most_common_items_of_user[k]\n            new_order[k] = pred_value\n        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n        \n    elif user in positive_items_per_user3.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user3[user]).most_common()}\n        user_index = userindexes[user]\n        new_order = {}\n        for k in list(most_common_items_of_user.keys())[:20]:\n            try:\n                itemindex = svd.items.index(k)\n                pred_value = np.dot(svd.userfeatures[user_index], svd.itemfeatures[itemindex].T) + svd.item_bias[0, itemindex]\n            except:\n                pred_value = most_common_items_of_user[k]\n            new_order[k] = pred_value\n        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n        \n    elif user in positive_items_per_user4.keys():\n        most_common_items_of_user = {k:v for k, v in Counter(positive_items_per_user4[user]).most_common()}\n        user_index = userindexes[user]\n        new_order = {}\n        for k in list(most_common_items_of_user.keys())[:20]:\n            try:\n                itemindex = svd.items.index(k)\n                pred_value = np.dot(svd.userfeatures[user_index], svd.itemfeatures[itemindex].T) + svd.item_bias[0, itemindex]\n            except:\n                pred_value = most_common_items_of_user[k]\n            new_order[k] = pred_value\n        user_output += [k for k, v in sorted(new_order.items(), key=lambda item: item[1])][:12]\n    \n    if user in user_group_dict:\n        item_his = user_group_dict[user][::-1]\n        for item in item_his:\n            if item in pred_next and pred_next[item] not in user_output:\n                user_output += [pred_next[item]]\n    if len(user_output) > 12:\n        user_output = user_output[:12]\n        \n    if len(user_output) < 12:\n        user_output += list(popular_items[:12 - len(user_output)])\n    \n    assert(len(user_output) == 12) \n    user_output = ' '.join(user_output)\n    result.append([user, user_output])","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:35:14.856635Z","iopub.execute_input":"2022-05-06T00:35:14.857395Z","iopub.status.idle":"2022-05-06T00:50:39.227897Z","shell.execute_reply.started":"2022-05-06T00:35:14.857344Z","shell.execute_reply":"2022-05-06T00:50:39.2267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.1 Result to Dataframe","metadata":{}},{"cell_type":"code","source":"result = pd.DataFrame(result)\nresult.columns = [\"customer_id\", 'prediction']\nresult","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:51:26.152396Z","iopub.execute_input":"2022-05-06T00:51:26.15272Z","iopub.status.idle":"2022-05-06T00:51:26.712624Z","shell.execute_reply.started":"2022-05-06T00:51:26.152689Z","shell.execute_reply":"2022-05-06T00:51:26.71158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5.2 Result Submission","metadata":{}},{"cell_type":"code","source":"result.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-06T00:51:31.198925Z","iopub.execute_input":"2022-05-06T00:51:31.199261Z","iopub.status.idle":"2022-05-06T00:51:44.583107Z","shell.execute_reply.started":"2022-05-06T00:51:31.199208Z","shell.execute_reply":"2022-05-06T00:51:44.582319Z"},"trusted":true},"execution_count":null,"outputs":[]}]}